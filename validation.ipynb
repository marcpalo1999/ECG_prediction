{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import pipeline modules\n",
    "from src.data_processing import load_processed_data\n",
    "from src.auxiliary import pathology_severity_groups, histogram_labels,analyze_feature_distributions\n",
    "from ecg_data_pipeline import ECGFeatureExtractor, CardiacConditionClassifier\n",
    "from ecg_model_pipeline import ECGModelTrainer, ModelVisualizer, BoundaryVisualizer\n",
    "\n",
    "# Load validation indices\n",
    "validation_indices_path = './Results/val_indices.npy'\n",
    "val_indices = np.load(validation_indices_path, allow_pickle=True)\n",
    "\n",
    "# Load validation data\n",
    "data_path = './Results/processed_data'\n",
    "val_ecg_dict, val_data = load_processed_data(data_path, indices=val_indices)\n",
    "print(f\"Loaded validation data for {len(val_data)} patients\")\n",
    "\n",
    "# Extract ECG signals\n",
    "val_ecg = {k: v['ecg_signals_filtered'] for k, v in val_ecg_dict.items()}\n",
    "del val_ecg_dict  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize condition classifier\n",
    "condition_classifier = CardiacConditionClassifier(pathology_hierarchy=pathology_severity_groups)\n",
    "\n",
    "# Transform diagnosis codes into cardiac condition categories\n",
    "val_data = condition_classifier.transform(val_data)\n",
    "val_labels = val_data['diagnosis_label']\n",
    "\n",
    "# Visualize class distribution\n",
    "pathology_order = sorted(\n",
    "    pathology_severity_groups.keys(),\n",
    "    key=lambda cat: pathology_severity_groups[cat]['severity'],\n",
    "    reverse=False\n",
    ")\n",
    "histogram_labels(val_labels, pathology_order=pathology_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature extractor\n",
    "feature_extractor = ECGFeatureExtractor(fs=500, features_to_extract=['hr_metrics', 'age'])\n",
    "\n",
    "# Extract features from ECG data\n",
    "extracted_features = feature_extractor.transform(val_ecg, val_data)\n",
    "\n",
    "# Combine with diagnosis label for analysis\n",
    "val_hrv = val_data[['diagnosis_label']].join(extracted_features)\n",
    "feature_names = ['median_hr', 'mean_hr', 'std_hr', 'min_hr', 'max_hr', 'age']\n",
    "\n",
    "# Feature distribution analysis\n",
    "analyze_feature_distributions(val_hrv, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = './Results/RF_model/ecg_rf_model.joblib'\n",
    "model_trainer = ECGModelTrainer.load(model_path)\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "# Create feature matrix and prepare for prediction\n",
    "X_val = val_hrv[feature_names]\n",
    "X_val_processed = model_trainer._preprocess_features(X_val)\n",
    "\n",
    "# Get label mapping for evaluation\n",
    "inv_mapping = {v: k for k, v in model_trainer.label_mapping.items()}\n",
    "ordered_classes = [inv_mapping[i] for i in range(len(inv_mapping))]\n",
    "y_val_encoded = np.array([model_trainer.label_mapping.get(label, -1) for label in val_labels])\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model_trainer.predict(X_val)\n",
    "y_pred_proba = model_trainer.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "visualizer = ModelVisualizer()\n",
    "\n",
    "# Plot confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "visualizer.plot_multiclass_confusion_matrix(y_val_encoded, y_pred, ordered_classes)\n",
    "\n",
    "# Create results dataframe with predictions\n",
    "val_results = val_data.copy()\n",
    "val_results['true_label_code'] = y_val_encoded\n",
    "val_results['predicted_label_code'] = y_pred\n",
    "val_results['true_label'] = [ordered_classes[i] for i in y_val_encoded]\n",
    "val_results['predicted_label'] = [ordered_classes[i] for i in y_pred]\n",
    "val_results['correct'] = (y_val_encoded == y_pred).astype(int)\n",
    "\n",
    "# Age group analysis\n",
    "val_results['age_group'] = pd.cut(\n",
    "    val_results['age'], \n",
    "    bins=[0, 40, 65, 100], \n",
    "    labels=['<40', '40-65', '>65']\n",
    ")\n",
    "\n",
    "# Performance by age group\n",
    "print(\"\\nPerformance by Age Group:\")\n",
    "for age_group in val_results['age_group'].unique():\n",
    "    group_idx = val_results['age_group'] == age_group\n",
    "    if np.sum(group_idx) > 0:\n",
    "        accuracy = np.mean(val_results.loc[group_idx, 'correct'])\n",
    "        print(f\"  Age {age_group}: {accuracy:.3f} accuracy ({np.sum(group_idx)} patients)\")\n",
    "\n",
    "# Performance by cardiac condition\n",
    "print(\"\\nPerformance by Cardiac Condition:\")\n",
    "for i, condition in enumerate(ordered_classes):\n",
    "    condition_idx = (y_val_encoded == i)\n",
    "    if np.sum(condition_idx) > 0:\n",
    "        accuracy = np.mean(val_results.loc[condition_idx, 'correct'])\n",
    "        print(f\"  {condition}: {accuracy:.3f} accuracy ({np.sum(condition_idx)} patients)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all classes\n",
    "print(\"\\nROC Curves (One-vs-All):\")\n",
    "roc_auc = visualizer.plot_one_vs_all_multiclass_roc(y_val_encoded, y_pred_proba, ordered_classes)\n",
    "\n",
    "# Plot ROC curves for each condition vs normal\n",
    "print(\"\\nROC Curves (One-vs-Normal):\")\n",
    "visualizer.plot_one_vs_normal_roc(y_val_encoded, y_pred_proba, ordered_classes, normal_idx=0)\n",
    "\n",
    "# Summarize ROC AUC values\n",
    "print(\"\\nROC AUC Values:\")\n",
    "for i, class_name in enumerate(ordered_classes):\n",
    "    print(f\"  {class_name}: {roc_auc[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define severity levels\n",
    "severity_levels = {condition: pathology_severity_groups[condition]['severity'] \n",
    "                  for condition in pathology_severity_groups.keys()}\n",
    "\n",
    "# Add severity to results\n",
    "val_results['true_severity'] = val_results['true_label'].map(severity_levels)\n",
    "val_results['predicted_severity'] = val_results['predicted_label'].map(severity_levels)\n",
    "val_results['severity_error'] = val_results['true_severity'] - val_results['predicted_severity']\n",
    "\n",
    "# Critical misclassifications: severe conditions predicted as normal or benign\n",
    "critical_misclass = val_results[\n",
    "    (val_results['correct'] == 0) & \n",
    "    (val_results['true_severity'] >= 5) & \n",
    "    (val_results['predicted_severity'] <= 2)\n",
    "]\n",
    "\n",
    "print(\"\\nCritical Misclassifications (High Severity as Normal/Benign):\")\n",
    "print(f\"Total: {len(critical_misclass)} patients ({len(critical_misclass)/len(val_results):.1%} of validation set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundaries in PCA space\n",
    "print(\"\\nVisualizing decision boundaries in PCA space:\")\n",
    "BoundaryVisualizer.plot_decision_space(\n",
    "    X_val_processed, \n",
    "    y_val_encoded, \n",
    "    model_trainer.model, \n",
    "    ordered_classes, \n",
    "    binary=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation summary\n",
    "output_dir = './Results/validation'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, 'validation_summary.txt'), 'w') as f:\n",
    "    f.write(\"ECG Classification Model Validation\\n\")\n",
    "    f.write(\"===================================\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Validation set size: {len(val_indices)} patients\\n\")\n",
    "    \n",
    "    f.write(\"\\nPerformance Metrics:\\n\")\n",
    "    f.write(\"--------------------------\\n\")\n",
    "    # Calculate overall metrics\n",
    "    accuracy = np.mean(y_val_encoded == y_pred)\n",
    "    f.write(f\"Overall accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    f.write(\"\\nClass-specific performance:\\n\")\n",
    "    for i, cls_name in enumerate(ordered_classes):\n",
    "        class_mask = (y_val_encoded == i)\n",
    "        if np.sum(class_mask) > 0:\n",
    "            cls_acc = np.mean(y_pred[class_mask] == i)\n",
    "            f.write(f\"  {cls_name}: {cls_acc:.4f} (n={np.sum(class_mask)})\\n\")\n",
    "    \n",
    "    # Critical errors\n",
    "    f.write(f\"\\nCritical misclassifications: {len(critical_misclass)} ({len(critical_misclass)/len(val_results):.1%} of validation set)\\n\")\n",
    "    \n",
    "    f.write(\"\\nROC AUC Values:\\n\")\n",
    "    for i, class_name in enumerate(ordered_classes):\n",
    "        f.write(f\"  {class_name}: {roc_auc[i]:.4f}\\n\")\n",
    "\n",
    "print(f\"\\nValidation results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "- **Consistency**: Similar metrics between development and validation datasets (generalization confirmed)\n",
    "- **Overall accuracy**: ~60% with better AUC (~0.80) than precision/recall (~0.40)\n",
    "- **Age-dependent performance**: Best in 40-65 age group, significantly worse in >65 patients\n",
    "\n",
    "## Strengths\n",
    "- **Normal ECG detection**: High sensitivity (~92%) across datasets\n",
    "- **Primary Electrical Disorders**: Good detection (~70-72%)\n",
    "- **Normal vs. Abnormal**: Strong discrimination (all conditions vs. Normal AUCs â‰¥0.83 except \"Others\")\n",
    "\n",
    "## Critical Weaknesses\n",
    "- **Dangerous misclassifications**: 12% of high-severity conditions misclassified as normal/benign\n",
    "- **Conduction System Disease**: 60.2% misclassified as benign/normal\n",
    "- **Ischemic Disorders**: 38.8% misclassified as benign/normal (8.2% as Normal)\n",
    "- **Poor discrimination**: Chamber Abnormalities (AUC 0.66-0.67) and Ischemic Disorders (AUC 0.67-0.68)\n",
    "\n",
    "## Feature Analysis\n",
    "- **Importance ranking**: std_hr > mean_hr > median_hr > age > max_hr > min_hr\n",
    "- **Feature stability**: High rank stability (0.88)\n",
    "- **PCA projection**: Significant class overlap with PC1 driven by HR metrics, PC2 by age\n",
    "- **Feature insufficiency**: Current features inadequate for morphologically distinct conditions\n",
    "\n",
    "## Future Implementations\n",
    "1. Implement ECG morphology features (PR intervals, QRS width, ST elevation) and frequency domain features\n",
    "2. Adopt hierarchical classification (normal/abnormal first, then specific condition)\n",
    "3. Apply class balancing techniques for minority classes\n",
    "4. Develop condition-specific classification thresholds\n",
    "5. Implement age-stratified models to address elderly performance gap\n",
    "\n",
    "The current model confirms limitations identified in main.ipynb: insufficient features, imbalanced data, and clinically unacceptable misclassifications of high-severity conditions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
