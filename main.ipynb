{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-lead ECG disease prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -V > full_requirements.txt && pip list --format=freeze >> full_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_processing import load_processed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cardiac_condition(diagnosis_codes):\n",
    "    pathology_hierarchy = {\n",
    "        'Structural': {\n",
    "            'codes': [\n",
    "                '22298006',   # Myocardial Infarction\n",
    "                '164865005',  # ST Segment Elevation\n",
    "                '164867002',  # ST Segment Depression\n",
    "                '164873001',  # Left Ventricular Hypertrophy\n",
    "                '164874007'   # Right Ventricular Hypertrophy\n",
    "            ],\n",
    "            'severity': 5\n",
    "        },\n",
    "        'Arrhythmia': {\n",
    "            'codes': [\n",
    "                '49436004',   # Atrial Fibrillation\n",
    "                '164896001',  # Ventricular Fibrillation\n",
    "                '426761007',  # Ventricular Tachycardia\n",
    "                '427172004'   # Premature Ventricular Contractions\n",
    "            ],\n",
    "            'severity': 4\n",
    "        },\n",
    "        'Conduction': {\n",
    "            'codes': [\n",
    "                '27885002',   # Complete Heart Block\n",
    "                '445211001',  # 2nd Degree Atrioventricular Block\n",
    "                '28189009',   # Left Bundle Branch Block\n",
    "                '59118001'    # Right Bundle Branch Block\n",
    "            ],\n",
    "            'severity': 3\n",
    "        },\n",
    "        'Rhythm Variant': {\n",
    "            'codes': [\n",
    "                '251146004',  # Sinus Tachycardia\n",
    "                '427393009',  # Sinus Bradycardia\n",
    "                '195126007'   # Atrial Tachycardia\n",
    "            ],\n",
    "            'severity': 2\n",
    "        },\n",
    "        'Normal': {\n",
    "            'codes': ['426783006'],  # Normal Sinus Rhythm\n",
    "            'severity': 1\n",
    "        },\n",
    "        'Other': {\n",
    "            'codes': [],  # Catch-all for unclassified diagnoses\n",
    "            'severity': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Find matching categories\n",
    "    matching_categories = [\n",
    "        category for category, details in pathology_hierarchy.items()\n",
    "        if any(code in diagnosis_codes for code in details['codes'])\n",
    "    ]\n",
    "    \n",
    "    # If multiple matches, select highest severity\n",
    "    if matching_categories:\n",
    "        return max(\n",
    "            matching_categories, \n",
    "            key=lambda cat: pathology_hierarchy[cat]['severity']\n",
    "        )\n",
    "    \n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Execute first time (to define index split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try loading preprocessed data\n",
    "# data_path = '/Users/marcpalomer/Documents/Personal/ECG_prediction/Results/processed_data'\n",
    "# try:\n",
    "#    ecg_data, patient_data = load_processed_data(data_path)\n",
    "#    print(f\"Loaded data for {len(ecg_data)} patients\")\n",
    "# except (FileNotFoundError, StopIteration):\n",
    "#    raise FileNotFoundError(\"Preprocessed data not found. Please run data_processing.py first\")\n",
    "\n",
    "\n",
    "# # Define stratification based on diagnosis\n",
    "# patient_data['diagnosis_class'] = patient_data['diagnosis_code'].apply(classify_cardiac_condition)\n",
    "\n",
    "# # Create development and validation sets (70/30 split)\n",
    "# dev_indices, val_indices = train_test_split(\n",
    "#     patient_data.index,\n",
    "#     test_size=0.7,\n",
    "#     random_state=42,\n",
    "#     stratify=patient_data['diagnosis_class']\n",
    "# )\n",
    "\n",
    "# del ecg_data\n",
    "# del patient_data\n",
    "\n",
    "# # Save indices for reproducibility\n",
    "# np.save('./Results/dev_indices.npy', dev_indices)\n",
    "# np.save('./Results/val_indices.npy', val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Initial Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation indices\n",
    "dev_indices = np.load('./Results/dev_indices.npy', allow_pickle=True)\n",
    "val_indices = np.load('./Results/val_indices.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Results/processed_data'\n",
    "try:\n",
    "   dev_ecg_dict, dev_data = load_processed_data(data_path, indices= dev_indices)\n",
    "   print(f\"Loaded data for {len(dev_data)} patients\")\n",
    "except (FileNotFoundError, StopIteration):\n",
    "   raise FileNotFoundError(\"Preprocessed data not found. Please run data_processing.py first\")\n",
    "\n",
    "dev_ecg = {k: v['ecg_signals_filtered'] for k, v in dev_ecg_dict.items()}\n",
    "del dev_ecg_dict\n",
    "\n",
    "print(\"Development set size:\", len(dev_indices))\n",
    "print(\"Validation set size:\", len(val_indices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ecg['JS39860'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illness distribution and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['diagnosis_label'] = dev_data['diagnosis_code'].apply(classify_cardiac_condition)\n",
    "dev_labels = dev_data['diagnosis_label']\n",
    "dev_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to dataframe\n",
    "dev_labels.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling others class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'labels' is a pandas Series containing the class labels\n",
    "largest_class_size =dev_labels.value_counts()[2]\n",
    "largest_class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the size of the largest non-'Other' class\n",
    "\n",
    "# Downsample the 'Other' class\n",
    "others_indices = dev_labels[dev_labels == 'Other'].index\n",
    "downsampled_others = np.random.choice(others_indices, size=largest_class_size, replace=False)\n",
    "\n",
    "# Create balanced dataset\n",
    "balanced_indices = dev_labels[dev_labels != 'Other'].index.tolist() + list(downsampled_others)\n",
    "\n",
    "# Update dev_ecg and dev_labels\n",
    "dev_ecg_downsized = {pid: dev_ecg[pid] for pid in dev_ecg.keys() if pid in balanced_indices}\n",
    "dev_labels_downsized = dev_labels.loc[balanced_indices]\n",
    "dev_data_downsized = dev_data.loc[balanced_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to dataframe\n",
    "dev_labels_downsized.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original ECG records: {len(dev_ecg)}\")\n",
    "print(f\"Downsampled ECG records: {len(dev_ecg_downsized)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HRV calculation in lead II (gold standard) (it is a time saries for patient so like a new lead...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "\n",
    "def validate_rpeaks(rpeaks, fs):\n",
    "    # Remove physiologically impossible R-peaks\n",
    "    rr_intervals = np.diff(rpeaks) / fs\n",
    "    valid_rr = (rr_intervals >= 0.2) & (rr_intervals <= 2.0)  \n",
    "    valid_peaks = rpeaks[1:][valid_rr]\n",
    "    return valid_peaks\n",
    "\n",
    "def calculate_hr_metrics(rpeaks, fs):\n",
    "    rr_intervals = np.diff(rpeaks) / fs\n",
    "    hr = 60 / rr_intervals\n",
    "    return np.median(hr), np.mean(hr), np.std(hr), np.min(hr), np.max(hr)\n",
    "\n",
    "def calculate_heartrate(record, fs):\n",
    "    # Find R-peaks using neurokit2\n",
    "    rpeaks = list(nk.ecg_findpeaks(record, sampling_rate=fs).values())[0]\n",
    "    rpeaks = validate_rpeaks(rpeaks, fs)\n",
    "    return calculate_hr_metrics(rpeaks, fs)\n",
    "\n",
    "def add_hr_metrics(patient_data, ecg_data):\n",
    "    metrics = {'median_hr': [], 'mean_hr': [], 'std_hr': [], 'min_hr': [], 'max_hr': []}\n",
    "    \n",
    "    for id in patient_data.index:\n",
    "        if id in ecg_data:\n",
    "            lead_II = ecg_data[id].loc[:,'II']\n",
    "            try:\n",
    "                median_hr, mean_hr, std_hr, min_hr, max_hr = calculate_heartrate(lead_II, fs=500)\n",
    "            except:\n",
    "                median_hr, mean_hr, std_hr, min_hr, max_hr = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            metrics['median_hr'].append(median_hr)\n",
    "            metrics['mean_hr'].append(mean_hr)\n",
    "            metrics['std_hr'].append(std_hr)\n",
    "            metrics['min_hr'].append(min_hr)\n",
    "            metrics['max_hr'].append(max_hr)\n",
    "        else:\n",
    "            for key in metrics:\n",
    "                metrics[key].append(None)\n",
    "    \n",
    "    for metric, values in metrics.items():\n",
    "        patient_data[metric] = values\n",
    "    \n",
    "    return patient_data\n",
    "\n",
    "dev_hrv = add_hr_metrics(dev_data_downsized, dev_ecg_downsized)\n",
    "dev_hrv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_features= ['median_hr',\t'mean_hr','std_hr',\t'min_hr', 'max_hr', 'age']\n",
    "ML_dataset = dev_hrv[analyse_features+['diagnosis_label']]\n",
    "# arrythmia_ml_dataset = ML_dataset[ML_dataset['cardiac_condition'].isin(['Normal','Arrhythmia'])]\n",
    "ML_dataset.value_counts('diagnosis_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import src.RF_pipeline as RF_pipeline\n",
    "import importlib\n",
    "importlib.reload(RF_pipeline)\n",
    "\n",
    "\n",
    "def prepare_data(df, target_col, features=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"Main function to analyze the model.\"\"\"\n",
    "    if features is None:\n",
    "        features = [col for col in df.columns if col != target_col]\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    analyzer = RF_pipeline.RandomForestAnalyzer()\n",
    "    visualizer = RF_pipeline.ModelVisualizer()\n",
    "    # Preprocess data\n",
    "    X_processed, y_processed, y_mapping = analyzer.preprocess(X,y)\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, y_mapping, analyzer, visualizer, features\n",
    "   \n",
    "X_train, X_test, y_train, y_test, y_mapping, analyzer, visualizer, features = prepare_data(df=ML_dataset, target_col='diagnosis_label', features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validated performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "cv_results = analyzer.cross_validate(X_train, y_train)\n",
    "\n",
    "# Visualize cross-validation results\n",
    "visualizer.plot_cv_results(scores=cv_results, multiclass=True)\n",
    "\n",
    "# Optional: Print detailed metrics\n",
    "\n",
    "metrics = ['test_accuracy', 'test_precision_macro', 'test_recall_macro', 'test_f1_macro', 'test_balanced_accuracy']\n",
    "stats = ['Mean', 'Std']\n",
    "\n",
    "# Create empty lists to store values\n",
    "means = [np.mean(cv_results[metric]) for metric in metrics]\n",
    "stds = [np.std(cv_results[metric]) for metric in metrics]\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Mean': means,\n",
    "    'Std': stds\n",
    "})\n",
    "# Optional: Round the values to 4 decimal places\n",
    "df[['Mean', 'Std']] = df[['Mean', 'Std']].round(4)\n",
    "\n",
    "# Display the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_model = analyzer.get_fitted_model(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on test set\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Get class names from encoding dictionary\n",
    "classes = list(y_mapping.keys())\n",
    "\n",
    "# Plot multiclass ROC curves\n",
    "roc_auc = visualizer.plot_multiclass_roc(y_test, y_pred_proba, classes)\n",
    "\n",
    "# Print AUC for each class\n",
    "# print(\"\\nClass-wise AUC:\")\n",
    "# for cls, auc_val in zip(classes, roc_auc.values()):\n",
    "#     print(f\"{cls}: {auc_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def plot_5class_decision_space(X, y, model, class_names):\n",
    "   color_mapping = {\n",
    "       0: 'red', 1: 'blue', 2: 'green', \n",
    "       3: 'orange', 4: 'purple', 5: 'brown'\n",
    "   }\n",
    "   \n",
    "   reducer = PCA(n_components=2)\n",
    "   X_reduced = reducer.fit_transform(X)\n",
    "   \n",
    "   x_min, x_max = X_reduced[:, 0].min() - 1, X_reduced[:, 0].max() + 1\n",
    "   y_min, y_max = X_reduced[:, 1].min() - 1, X_reduced[:, 1].max() + 1\n",
    "   xx, yy = np.meshgrid(\n",
    "       np.linspace(x_min, x_max, 100),\n",
    "       np.linspace(y_min, y_max, 100)\n",
    "   )\n",
    "   \n",
    "   grid_reduced = np.c_[xx.ravel(), yy.ravel()]\n",
    "   grid_original = reducer.inverse_transform(grid_reduced)\n",
    "   \n",
    "   Z_proba = model.predict_proba(grid_original)\n",
    "   Z = np.argmax(Z_proba, axis=1)\n",
    "   \n",
    "   plt.figure(figsize=(12, 10))\n",
    "   \n",
    "   # Create a custom colormap with alpha\n",
    "   colors = [color_mapping[cls] for cls in np.unique(Z)]\n",
    "   alphas = [0.2] * len(colors)\n",
    "   \n",
    "   # Plot decision boundaries with unique colors\n",
    "   plt.tricontourf(grid_reduced[:, 0], grid_reduced[:, 1], Z, \n",
    "                   levels=len(np.unique(Z)), \n",
    "                   colors=colors, \n",
    "                   alpha=0.2)\n",
    "   \n",
    "   inverted_classnames = {v: k for k, v in class_names.items()}\n",
    "   for cls in np.unique(y):\n",
    "       mask = (y == cls)\n",
    "       plt.scatter(\n",
    "           X_reduced[mask, 0], \n",
    "           X_reduced[mask, 1], \n",
    "           color=color_mapping[cls],\n",
    "           edgecolor='black', \n",
    "           s=30,\n",
    "           label=inverted_classnames[cls]\n",
    "       )\n",
    "   plt.legend(title='Classes', loc='best', markerscale=2)   \n",
    "   plt.title('5-Class Decision Boundaries')\n",
    "   plt.xlabel('PCA Component 1')\n",
    "   plt.ylabel('PCA Component 2')\n",
    "   plt.show()\n",
    "   \n",
    "   return X_reduced\n",
    "\n",
    "# Usage example\n",
    "X_pca = plot_5class_decision_space(X_test, y_test, model=rf_model, class_names=y_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "visualizer.plot_multiclass_confusion_matrix(y_test, y_pred, list(y_mapping.keys()), normalise = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear both from PCA space coloring and from confussion matrix that RF model is able to identify \"Normal\" patients vs other categories, but is not so good at differentiating between the different cardiopathological families we have defined. \n",
    "\n",
    "An interesting approach to implement here would be to generate an ensamble model, first lasssifying between Normal and abnormal and later trying to differentiate between the different abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final ML dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare full training data\n",
    "X_full_train = pd.concat([X_train, X_test])\n",
    "y_full_train = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Train final model\n",
    "final_model = RF_pipeline.RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_full_train, y_full_train)\n",
    "\n",
    "# Optional: Save the model\n",
    "joblib.dump(final_model, './Results/final_ml_model.joblib')\n",
    "\n",
    "# Verify model performance\n",
    "y_pred = final_model.predict(X_full_train)\n",
    "visualizer.plot_multiclass_confusion_matrix(y_full_train, y_pred, list(y_mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF model is correltly overfitting in train, as it is expected in such method, meaning that possibly it is at lease catching the patterns inside data. Further testing on external validation data will assess if such learned pattern corresponds to signal in the data or to noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "analyzer = RF_pipeline.RandomForestAnalyzer()\n",
    "analyzer.save_model(final_model, X_full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL CNN prediction: \n",
    "- Will we beat HRV RF classification?\n",
    "\n",
    "### Training Phase\n",
    "1. **Data Preparation**\n",
    "  - Raw ECG dictionary + labels → `prepare_data()` → `normalize_signals()`\n",
    "  - Train/val/test split\n",
    "  - Dataset & DataLoader creation for batching\n",
    "\n",
    "2. **Training Cycle**\n",
    "  - DataLoader feeds batches to ModelTrainer\n",
    "  - Forward pass through ECGNet\n",
    "  - Loss calculation, backpropagation\n",
    "  - Validation performance check\n",
    "  - Save best model\n",
    "  - Track metrics history\n",
    "\n",
    "### Evaluation Phase\n",
    "1. **Model Assessment**\n",
    "  - Load best model weights\n",
    "  - Full forward pass on test set\n",
    "  - Generate predictions/probabilities\n",
    "\n",
    "2. **Results**\n",
    "  - Performance metrics calculation\n",
    "  - Visualization generation\n",
    "  - Save all results\n",
    "\n",
    "## DL Architecture\n",
    "\n",
    "### Input Processing\n",
    "- 12-lead ECG signals\n",
    "- 5000 timepoints per lead\n",
    "- Normalized per lead\n",
    "\n",
    "### Feature Extraction\n",
    "- Conv1d (k=50): QRS complex detection\n",
    "- Conv1d (k=7): Wave morphology\n",
    "- Conv1d (k=5): Fine details\n",
    "- Increasing channels (12→32→64→128) for feature hierarchy\n",
    "\n",
    "### Each Conv Block\n",
    "- BatchNorm: Training stability\n",
    "- ReLU: Non-linearity\n",
    "- MaxPool: Dimension reduction\n",
    "\n",
    "### Classification\n",
    "- AdaptivePool: Fixed output size\n",
    "- FC layers (6400→256→64→2)\n",
    "- Dropout layers prevent overfitting\n",
    "- Output: Binary classification probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dev_labels_downsized_array = dev_labels_downsized.map(y_mapping)\n",
    "\n",
    "print(\"\\nLabel encoding dictionary:\")\n",
    "for code, label in y_mapping.items():\n",
    "    print(f\"{label} -> {code}\")\n",
    "\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(dev_labels_downsized_array.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in a dictionary like {patient_id: DataFrame(500x12)}\n",
    "dev_ecg_downsized_array = []\n",
    "for patient_id in dev_ecg_downsized:\n",
    "    df = dev_ecg_downsized[patient_id]\n",
    "    signal = df.values.T  # Transpose to get (12, 500)\n",
    "    dev_ecg_downsized_array.append(signal)\n",
    "\n",
    "dev_ecg_downsized_array = np.array(dev_ecg_downsized_array)  # Shape: (n_patients, 12, 500)\n",
    "dev_labels_downsized_array = np.array(dev_labels_downsized_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ecg_downsized_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels_downsized_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL model training/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables to keep\n",
    "keep = ['importlib', 'CNN_pipeline', 'tf','np','train_test_split','model', 'X_val', 'y_val', 'signals', 'labels', 'y_mapping']\n",
    "import gc\n",
    "\n",
    "def clean_memory(keep_vars=[]):\n",
    "   \"\"\"\n",
    "   Free memory while keeping specified variables.\n",
    "   Args:\n",
    "       keep_vars (list): Names of variables to keep\n",
    "   \"\"\"\n",
    "   # Store variables to keep\n",
    "   saved = {var: globals()[var] for var in keep_vars if var in globals()}\n",
    "   \n",
    "   # Clear globals\n",
    "   for var in list(globals()):\n",
    "       if var not in ['gc', 'clean_memory'] + keep_vars:\n",
    "           del globals()[var]\n",
    "           \n",
    "   # Restore saved variables\n",
    "   globals().update(saved)\n",
    "   \n",
    "   # Force garbage collection\n",
    "   gc.collect()\n",
    "\n",
    "# Usage example:\n",
    "# clean_memory(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.CNN_pipeline as CNN_pipeline\n",
    "# importlib.reload(CNN_pipeline)\n",
    "# # Initialize model\n",
    "# model = CNN_pipeline.ECGClassifier(\n",
    "#     input_shape=(dev_ecg_downsized_array.shape[1], dev_ecg_downsized_array.shape[2]), \n",
    "#     encode_dict=y_mapping\n",
    "# )\n",
    "\n",
    "# X_train_CNN, X_val_CNN, y_train_CNN, y_val_CNN = train_test_split(dev_ecg_downsized_array, dev_labels_downsized_array, test_size=0.25)\n",
    "# # del signals\n",
    "# # del labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_val_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y_train_CNN, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y_val_CNN, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model is nicely prepared to get trained on n different classes of data. It consists of the structure mentioned above plus some callbacks:\n",
    "\n",
    "- EarlyStopping:\n",
    "\n",
    "    - Stops training when validation loss stops improving\n",
    "    - Prevents overfitting\n",
    "    - Saves best model weights\n",
    "\n",
    "\n",
    "- ModelCheckpoint:\n",
    "\n",
    "    - Saves model weights at best validation performance\n",
    "    - Allows recovery of best model after training\n",
    "\n",
    "\n",
    "- ReduceLROnPlateau:\n",
    "\n",
    "    - Dynamically reduces learning rate when metrics plateau\n",
    "    - Helps model fine-tune and escape local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train\n",
    "# del X_train\n",
    "# del y_train\n",
    "# history = model.train(X_train_CNN, y_train_CNN, X_val_CNN, y_val_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load weights\n",
    "# model.load_model('./Results/final_CNN_model/best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate\n",
    "# importlib.reload(CNN_pipeline)\n",
    "\n",
    "# metrics = model.evaluate(X_train_CNN, y_train_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = model.evaluate(X_val_CNN, y_val_CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from both the train and validation plots that the model is not able to fit the training data, even less generalise corrrectly. The model is underfitting our data. What can we do to solve this?\n",
    "\n",
    "Farzad Nobar has a cool article on this: https://medium.com/towards-data-science/machine-learning-basics-i-look-for-in-data-scientist-interviews-a6ff25be38c9\n",
    "\n",
    "It indicates that we can increase model complexity (not interesting), for complex models increase training size (yes interesting) or decrease regularizations or other techniques to prevent overfitting (as dropout etc) (yes interesting)\n",
    "\n",
    "- Lets think about this for some days..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative CNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels range:\", dev_labels_downsized_array.min(), \"-\", dev_labels_downsized_array.max())\n",
    "print(\"Unique labels:\", np.unique(dev_labels_downsized_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_mapping:\", y_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 50,\n",
    "    'seed': 42\n",
    "}\n",
    "import Alternative_CNN\n",
    "importlib.reload(Alternative_CNN)\n",
    "\n",
    "results = Alternative_CNN.main(signals=dev_ecg_downsized_array, labels = dev_labels_downsized_array, label_mapping=y_mapping, config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the plots + explaination of what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
